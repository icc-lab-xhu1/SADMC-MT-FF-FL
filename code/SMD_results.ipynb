{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18034809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T14:37:31.505583Z",
     "start_time": "2023-03-07T14:37:31.492643Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import network as net\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eddbc487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T14:37:32.053704Z",
     "start_time": "2023-03-07T14:37:32.038469Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExternalAttention(nn.Module):\n",
    "    def __init__(self, d_model, S=64):\n",
    "        super().__init__()\n",
    "        self.mk = nn .Linear(d_model,S,bias=False)\n",
    "        self.mv = nn .Linear(S,d_model,bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, queries):\n",
    "        attn = self.mk(queries)\n",
    "        attn = self.softmax(attn)\n",
    "        attn = attn / torch.sum(attn, dim=2, keepdim=True)\n",
    "        out = self.mv(attn)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37746fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T14:37:32.872399Z",
     "start_time": "2023-03-07T14:37:32.858411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([122, 1, 38])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(122,1,38)\n",
    "m = ExternalAttention(d_model=38, S=8)\n",
    "y = m(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eef1315b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T11:36:46.183014Z",
     "start_time": "2023-03-08T11:36:46.158049Z"
    }
   },
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class MLSTM(nn.Module):\n",
    "    def __init__(self, ni, nf, fc_drop_p=0.3):\n",
    "        super(MLSTM, self).__init__()\n",
    "         \n",
    "        self.fc_drop_p = fc_drop_p\n",
    "        self.num_classes = nf\n",
    "        self.num_lstm_layers = 2\n",
    "        self.num_lstm_out = 128\n",
    "\n",
    "        self.conv1_nf = 128\n",
    "        self.conv2_nf = 256\n",
    "        self.conv3_nf = 128\n",
    "        \n",
    "        self.se1 = SELayer(self.conv1_nf)  # ex 128\n",
    "        self.se2 = SELayer(self.conv2_nf)  # ex 256\n",
    "            \n",
    "        self.conv1 = nn.Conv1d(1, self.conv1_nf, kernel_size=7, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(self.conv1_nf, self.conv2_nf, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv1d(self.conv2_nf, self.conv3_nf, kernel_size=3, stride=1, padding=2)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.bn2 = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.bn3 = nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.ea = ExternalAttention(d_model=self.num_lstm_out, S=64)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=ni, \n",
    "                            hidden_size=self.num_lstm_out,\n",
    "                            num_layers=self.num_lstm_layers,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(self.conv3_nf+self.num_lstm_out, self.num_classes)\n",
    "        self.convDrop = nn.Dropout(self.fc_drop_p)\n",
    "#         self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.bn1.weight,val=1)\n",
    "        nn.init.constant_(self.bn2.weight,1)\n",
    "        nn.init.constant_(self.bn3.weight,val=1)\n",
    "        nn.init.constant_(self.conv1.bias,val=0)\n",
    "        nn.init.constant_(self.bn1.bias,val=0)\n",
    "        nn.init.constant_(self.conv2.bias,val=0)\n",
    "        nn.init.constant_(self.bn2.bias,val=0)\n",
    "        nn.init.constant_(self.conv3.bias,val=0)\n",
    "        nn.init.constant_(self.bn3.bias,val=0)\n",
    "        nn.init.constant_(self.fc.bias,val=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1, (ht,ct) = self.lstm(x)\n",
    "        x1 = self.ea(x1)\n",
    "        x1 = x1[:,-1,:]\n",
    "        \n",
    "        x2 = self.convDrop(self.relu(self.bn1(self.conv1(x))))\n",
    "        x2 = self.se1(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn2(self.conv2(x2))))\n",
    "        x2 = self.se2(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn3(self.conv3(x2))))\n",
    "        x2 = torch.mean(x2,2)\n",
    "        \n",
    "        x_all = torch.cat((x1,x2),dim=1)\n",
    "        x_out = self.fc(x_all)\n",
    "        x_out = F.log_softmax(x_out, dim=1)\n",
    "        \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ff8fd79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T11:36:46.671043Z",
     "start_time": "2023-03-08T11:36:46.606508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([122, 2])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(122,1,31)\n",
    "m = MLSTM(31,2)\n",
    "y = m(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc2f937b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T11:36:47.241274Z",
     "start_time": "2023-03-08T11:36:47.232025Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "class LoadData(Dataset):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.len = len(self.train_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.train_x[index], self.train_y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f787141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T11:36:47.623981Z",
     "start_time": "2023-03-08T11:36:47.598541Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_test(class_name, train_loader, test_loader, num_classes, length):\n",
    "    epoches = 60\n",
    "    lr = 0.02  #\n",
    "    input_num = 1\n",
    "    output_num = num_classes\n",
    "    loss_list = []\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # model = net.MLSTM_test(length, num_classes)\n",
    "    model = net.BasicFCN(input_num, num_classes, length)\n",
    "    # model = MLSTM(length, num_classes)\n",
    "    # model = MLSTM(length, num_classes)\n",
    "    model.to(device)\n",
    "    #     loss_func = nn.NLLLoss()\n",
    "    #     optimizer = optim.Adam(model.parameters(), lr=lr)  #\n",
    "    alpha = 1.0\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    acc = 0\n",
    "    all_t = 0\n",
    "    all_f = 0\n",
    "    pre_t = 0\n",
    "    pre_f = 0\n",
    "    all_2 = 0\n",
    "    all_3 = 0\n",
    "    pre_2 = 0\n",
    "    pre_3 = 0\n",
    "    preright_2 = 0\n",
    "    preright_3 = 0\n",
    "    TN = 0\n",
    "    preright_f = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model_Tstate = None\n",
    "    y_true = []\n",
    "    y_pre = []\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        epoch_loss_list = []\n",
    "        for images, labels in train_loader:\n",
    "            model.train()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = images.float()\n",
    "            # lam = np.random.beta(alpha, alpha)#生成符合Beta分布的值\n",
    "            # index = torch.randperm(images.size(0)).cuda()\n",
    "            # mixed_x = lam * images + (1 - lam) * images[index, :]\n",
    "            # pred = model(mixed_x)\n",
    "            # loss = lam * loss_func(pred, labels)  + (1 - lam) * loss_func(pred, labels[index])\n",
    "            pred = model(images)\n",
    "            loss = loss_func(pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss_list.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                model.eval()\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                images = images.float()\n",
    "                all_t += (labels == 0).sum().item()  # 正常样本数\n",
    "                all_f += (labels == 1).sum().item()  # 异常样本数\n",
    "                output = model(images)\n",
    "                values, predicte = torch.max(output, 1)\n",
    "                total += labels.size(0)\n",
    "                y_true.append(labels)\n",
    "                y_pre.append(predicte)\n",
    "                pre_f += (predicte == 1).sum().item()  # 预测出的异常样本数\n",
    "                if num_classes == 4:\n",
    "                    all_2 += (labels == 2).sum().item()  # 异常样本数\n",
    "                    all_3 += (labels == 3).sum().item()  # 异常样本数\n",
    "                    pre_2 += (predicte == 2).sum().item()  # 预测出的异常样本数\n",
    "                    pre_3 += (predicte == 3).sum().item()  # 预测出的异常样本数\n",
    "                    preright_2 += ((predicte == 2) and (predicte == labels)).sum().item()\n",
    "                    preright_3 += ((predicte == 3) and (predicte == labels)).sum().item()\n",
    "                TN += ((predicte == 0) and (predicte == labels)).sum().item()\n",
    "                preright_f += ((predicte == 1) and (predicte == labels)).sum().item()\n",
    "                correct += (predicte == labels).sum().item()\n",
    "        if (correct / total) > acc:\n",
    "            acc = correct / total\n",
    "            # print(\"The {} accuracy of epoch {} TSC: {}%\".format(class_name,epoch+1, 100 * correct / total))\n",
    "            # torch.save(model.state_dict(), \"FedTemp1/\" + class_name + \".pkl\")\n",
    "            model_Tstate = model\n",
    "\n",
    "        loss_list.append(np.mean(epoch_loss_list))\n",
    "    acc = correct / total  # 准确率\n",
    "    pre = preright_f / pre_f  # 精确率\n",
    "    recall = preright_f / all_f  # 召回率\n",
    "    f1_score = 2 * pre * recall / (pre + recall)  # f1 score\n",
    "    if num_classes == 4:\n",
    "        pre2 = preright_2 / pre_2  # 精确率\n",
    "        recall2 = preright_2 / all_2  # 召回率\n",
    "        f1_score2 = 2 * pre2 * recall2 / (pre2 + recall2)  # f1 score\n",
    "        pre3 = preright_3 / pre_3  # 精确率\n",
    "        recall3 = preright_3 / all_3  # 召回率\n",
    "        f1_score3 = 2 * pre3 * recall3 / (pre3 + recall3)  # f1 score\n",
    "        print('precision:{:.3f}, recall:{:.3f}, f1_score:{:.3f}'.format(pre2, recall2, f1_score2))\n",
    "        print('precision:{:.3f}, recall:{:.3f}, f1_score:{:.3f}'.format(pre3, recall3, f1_score3))\n",
    "    TP = preright_f\n",
    "    FP = pre_f - preright_f\n",
    "    FN = all_f - preright_f\n",
    "    MCC = ((TP * TN) - (FP * FN)) / math.sqrt((TP + FP) * (FN + TP) * (FN + TN) * (FP + TN))\n",
    "    print('precision:{:.3f}, recall:{:.3f}, f1_score:{:.3f}, MCC:{:.3f}'.format(pre, recall, f1_score, MCC))\n",
    "    if num_classes == 4:\n",
    "        micro_pre = (preright_f+preright_2+preright_3) / (pre_f+pre_2+pre_3)\n",
    "        mirco_recall  = (preright_f+preright_2+preright_3) / (all_f+all_2+all_3)\n",
    "        micro = 2 * micro_pre * mirco_recall / (micro_pre+mirco_recall)\n",
    "        macro_pre = (pre+pre2+pre3) / 3\n",
    "        macro_recall = (recall+recall2+recall3) / 3\n",
    "        macro = (f1_score + f1_score2 + f1_score3)/3\n",
    "        macro = 2 * macro_pre * macro_recall / (macro_pre + macro_recall)\n",
    "        print('macro:{:.3f}, micro:{:.3f}'.format(macro, micro))\n",
    "    return y_true, y_pre, model_Tstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79485736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T11:36:48.086644Z",
     "start_time": "2023-03-08T11:36:48.073775Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_name = ['machine-1-1_test.csv','machine-1-2_test.csv','machine-1-3_test.csv','machine-1-4_test.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e95dca97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T11:36:48.456019Z",
     "start_time": "2023-03-08T11:36:48.440345Z"
    }
   },
   "outputs": [],
   "source": [
    "setup_seed(123)\n",
    "Fed_iteration = 10\n",
    "names = dir_name\n",
    "start_time = time.time()\n",
    "numbers = len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c1818f1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-08T11:36:48.894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19935, 39) (19935,)\n",
      "precision:0.857, recall:1.000, f1_score:0.923, MCC:0.918\n",
      "(16585, 39) (16585,)\n",
      "precision:1.000, recall:1.000, f1_score:1.000, MCC:1.000\n",
      "(16592, 39) (16592,)\n",
      "precision:1.000, recall:0.933, f1_score:0.965, MCC:0.965\n",
      "(16594, 39) (16594,)\n",
      "precision:1.000, recall:1.000, f1_score:1.000, MCC:1.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(names)):    \n",
    "    classname = names[i]\n",
    "#     x_train = np.load(\"Sliding_Window_data/\"+classname+\"_Xtrain.npy\")\n",
    "#     y_train = np.load(\"Sliding_Window_data/\"+classname+\"_Ytrain.npy\")\n",
    "#     x_test = np.load(\"Sliding_Window_data/\"+classname+\"_Xtest.npy\")\n",
    "#     y_test = np.load(\"Sliding_Window_data/\"+classname+\"_Ytest.npy\")\n",
    "    x_train = np.load(\"../data/\"+classname+\"_Xtrain.npy\")\n",
    "    y_train = np.load(\"../data/\"+classname+\"_Ytrain.npy\")\n",
    "    x_test = np.load(\"../data/\"+classname+\"_Xtest.npy\")\n",
    "    y_test = np.load(\"../data/\"+classname+\"_Ytest.npy\")\n",
    "    num_classes = y_test.shape[1]\n",
    "    length = x_train.shape[1]\n",
    "    y_test = np.argmax(y_test,axis=1)\n",
    "    y_train =  np.argmax(y_train,axis=1)\n",
    "    print(x_train.shape,y_train.shape)\n",
    "    x_train = x_train.reshape((x_train.shape[0],1,x_train.shape[1])).astype(np.float32)\n",
    "    x_test = x_test.reshape((x_test.shape[0],1,x_test.shape[1])).astype(np.float32)\n",
    "    train_loader = LoadData(x_train,y_train)\n",
    "    test_set = LoadData(x_test,y_test)\n",
    "    train_loader = dataloader.DataLoader(dataset=train_loader,batch_size=128,shuffle=True)\n",
    "    test_loader = dataloader.DataLoader(dataset=test_set,shuffle=False)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    y_true, y_pre, model_state = train_and_test(classname,train_loader,test_loader,num_classes, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
